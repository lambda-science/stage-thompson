{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('../../mismatch_db.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def fasta2List(pathFasta):\n",
    "    f = open(pathFasta, \"r\")\n",
    "    title = []\n",
    "    seq = []\n",
    "    seq_temp = []\n",
    "    for line in f:\n",
    "        if line[0] == \">\":\n",
    "            seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "            title.append(line.replace(\"\\n\", \"\"))\n",
    "            seq_temp = []\n",
    "        else:\n",
    "            seq_temp.append(line)\n",
    "    seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "    seq.pop(0)\n",
    "    dictionary = dict(zip(title, seq))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table mismatch\n",
    "error_list = pd.read_csv(\"../../data/mismatch-analysis/uniprot_errors_type3.txt\", sep=\" \", header=None)\n",
    "human_exon_pos = pd.read_csv(\"../../data/mismatch-flagging/human_mismatch_exon_pos.tab\", sep=\"\\t\")\n",
    "primate_exon_pos = pd.read_csv(\"../../data/mismatch-analysis/mismatch_exon_pos.tab\", sep=\"\\t\")\n",
    "\n",
    "# Script kirsley pr seq\n",
    "mismatch_prim = []\n",
    "mismatch_hum = []\n",
    "\n",
    "for index, row in error_list.iloc[:, :].iterrows():\n",
    "    fasta_name = row[0][58:-6]\n",
    "    Prot_list = fasta2List(\"../../data/raw/uniprot-blast/results/\"+fasta_name)\n",
    "    prot_prim = [val for key, val in Prot_list.items() if row[2] in key]\n",
    "    prot_hum = [val for key, val in Prot_list.items() if row[0]\n",
    "                [58:-15] in key]\n",
    "    mismatch_prim.append(prot_prim[0][row[3]:row[4]+1])\n",
    "    mismatch_hum.append(prot_hum[0][row[5]:row[6]+1])\n",
    "error_list.insert(7, \"seq_prim\", mismatch_prim, allow_duplicates=True)\n",
    "error_list.insert(8, \"seq_hum\", mismatch_hum, allow_duplicates=True)\n",
    "\n",
    "# Rename des col\n",
    "primate_exon_pos = primate_exon_pos.rename({\"Alignement\":\"prot_hum\", \"UniprotID\":\"prot_prim\", \"PosStartError\":\"pos_start_prim\", \"PosStopError\":\"pos_stop_prim\", \"FirstExonError\":\"exon_start_prim\", \"LastExonError\":\"exon_stop_prim\"},axis=1)\n",
    "human_exon_pos.drop([\"PosStartError_H\", \"PosStopError_H\"], axis=1, inplace=True)\n",
    "human_exon_pos = human_exon_pos.rename({\"Alignement\":\"prot_hum\", \"UniprotID\":\"prot_prim\", \"PosStartError_P\":\"pos_start_prim\", \"PosStopError_P\":\"pos_stop_prim\", \"FirstExonError\":\"exon_start_hum\", \"LastExonError\":\"exon_stop_hum\"},axis=1)\n",
    "error_list = error_list.rename({0:\"prot_hum\", 1:\"Error\", 2:\"prot_prim\", 3:\"pos_start_prim\", 4:\"pos_stop_prim\", 5:\"pos_start_hum\", 6:\"pos_stop_hum\"},axis=1)\n",
    "\n",
    "# Remplacement des erreur par NAN\n",
    "primate_exon_pos.replace(\"ERROR\", np.nan, inplace=True)\n",
    "human_exon_pos.replace(\"ERROR\", np.nan, inplace=True)\n",
    "# Merging des trois tableaux\n",
    "exon_pos = human_exon_pos.merge(primate_exon_pos, how=\"outer\", on=[\"prot_hum\", \"Error\", \"prot_prim\", \"pos_start_prim\", \"pos_stop_prim\"])\n",
    "error_list_db = error_list.merge(exon_pos, how='outer', on=[\"prot_hum\", \"Error\", \"prot_prim\", \"pos_start_prim\", \"pos_stop_prim\"])\n",
    "# Retyping (bug merge)\n",
    "error_list_db = error_list_db.astype({\"exon_start_prim\": \"float\", \"exon_stop_prim\":\"float\", \"exon_start_hum\": \"float\", \"exon_stop_hum\":\"float\"})\n",
    "error_list_db = error_list_db.astype({\"exon_start_prim\": \"Int64\", \"exon_stop_prim\":\"Int64\", \"exon_start_hum\": \"Int64\", \"exon_stop_hum\":\"Int64\"})\n",
    "# Reordering and substring\n",
    "error_list_db[\"mismatch_ID\"] = error_list_db.index\n",
    "error_list_db = error_list_db[[\"mismatch_ID\", \"prot_hum\", \"prot_prim\", \"pos_start_prim\", \"pos_stop_prim\", \"pos_start_hum\", \"pos_stop_hum\", \"exon_start_prim\", \"exon_stop_prim\", \"exon_start_hum\", \"exon_stop_hum\", \"seq_prim\", \"seq_hum\"]]\n",
    "error_list_db['prot_hum'] = error_list_db['prot_hum'].str[58:-15]\n",
    "error_list_db.to_sql(con=conn, name='mismatch', index=False, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Protein\n",
    "prot = fasta2List(\"../../data/raw/uniprot-blast/results/all_sequence.fasta\")\n",
    "primate_ensembl = pd.read_csv(\"../../data/mismatch-analysis/transcript_ensembl_corrected2.tab\", sep=\"\\t\")\n",
    "human_ensembl = pd.read_csv(\"../../data/mismatch-flagging/human_transcript_ensembl_corrected2.tab\", sep=\"\\t\")\n",
    "\n",
    "ensembl_uniprot = pd.concat([human_ensembl, primate_ensembl])\n",
    "ensembl_uniprot.rename(columns={'From':\"prot_ID\", 'To':\"transcript_ID\"}, inplace=True)\n",
    "prot_name = []\n",
    "orga = []\n",
    "seq = []\n",
    "\n",
    "for key, val in prot.items():\n",
    "    my_elem = key.split(\" \")\n",
    "    prot_name.append(my_elem[0][1:])\n",
    "    orga.append([x for x in my_elem if \"OX=\" in x][0][3:])\n",
    "    seq.append(val)\n",
    "my_dict = {'prot_ID': prot_name, 'sequence': seq, 'organism': orga}\n",
    "df = pd.DataFrame(my_dict)\n",
    "prot_table = df.merge(ensembl_uniprot, on=[\"prot_ID\"], how='left')\n",
    "prot_table.to_sql(con=conn, name='protein', index=False, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Transcript\n",
    "primate_ensembl = pd.read_csv(\"../../data/mismatch-analysis/transcript_ensembl_corrected2.tab\", sep=\"\\t\")\n",
    "human_ensembl = pd.read_csv(\"../../data/mismatch-flagging/human_transcript_ensembl_corrected2.tab\", sep=\"\\t\")\n",
    "primate_cds = fasta2List(\"../../data/mismatch-analysis/CDS_all_filt.fasta\")\n",
    "human_cds = fasta2List(\"../../data/mismatch-flagging/human_CDS_all_corrected_filt.fasta\")\n",
    "primate_genom = fasta2List(\"../../data/mismatch-analysis/genomic_all_filt.fasta\")\n",
    "human_genom = fasta2List(\"../../data/mismatch-flagging/human_genomic_all_corrected_filt.fasta\")\n",
    "human_cds.update(primate_cds)\n",
    "human_genom.update(primate_genom)\n",
    "ensembl_uniprot = pd.concat([human_ensembl, primate_ensembl])\n",
    "\n",
    "# Manipulation, merging, Ã©criture\n",
    "df_cds = pd.DataFrame({'transcript_ID': list(human_cds.keys()), 'sequence_CDS': list(human_cds.values())})\n",
    "df_cds['transcript_ID'] = df_cds['transcript_ID'].str.split(\" \")\n",
    "df_cds['transcript_ID'] = df_cds['transcript_ID'].str[0]\n",
    "df_cds['transcript_ID'] = df_cds['transcript_ID'].str[1:]\n",
    "df_genom = pd.DataFrame({'transcript_ID': list(human_genom.keys()), 'sequence_genomic': list(human_genom.values())})\n",
    "df_genom['transcript_ID'] = df_genom['transcript_ID'].str.split(\" \")\n",
    "df_genom['transcript_ID'] = df_genom['transcript_ID'].str[0]\n",
    "df_genom['transcript_ID'] = df_genom['transcript_ID'].str[1:]\n",
    "df_cds = df_cds.merge(df_genom, on='transcript_ID', how='outer')\n",
    "\n",
    "# To DB\n",
    "df_cds.to_sql(con=conn, name='transcript', index=False, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table exon_intron_map\n",
    "# stage-thompson/data$ cat mismatch-analysis2/Exon_map.tab mismatch-analysis2/Intron_map.tab mismatch-flagging/human_Exon_map.tab mismatch-flagging/human_Intron_map.tab > full_exon_intron_map.tab\n",
    "full_map = pd.read_csv(\"../../data/full_exon_intron_map.tab\", sep=\"\\t\", header=None)\n",
    "full_map.drop(0, axis=1, inplace=True)\n",
    "full_map = full_map.rename({1:\"transcript_ID\", 2:\"type\", 3:\"number_elem\", 4:\"pos_start_genom\", 5:\"pos_end_genom\", 6:\"seq\"},axis=1)\n",
    "full_map[\"transcript_index\"] = full_map.index\n",
    "full_map = full_map[[\"transcript_index\", \"transcript_ID\", \"type\", \"number_elem\", \"pos_start_genom\", \"pos_end_genom\", \"seq\"]]\n",
    "\n",
    "full_map.to_sql(con=conn, name='exon_intron_map', index=False, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table tblastn\n",
    "#tblastn = pd.read_csv(\"../../data/mismatch-analysis/tblastn/match.out\", sep=\"\\t\")\n",
    "tblastn = pd.read_csv(\"../../data/mismatch-analysis/tblastn2/match.out\", sep=\"\\t\")\n",
    "tblastn.drop([\"Match\", \"Similarity\", \"Length\", \"Frame\"], axis=1, inplace=True)\n",
    "tblastn = tblastn.rename({\"Primate\":\"prot_ID_prim\", \"Human\":\"prot_ID_hum\", \"Seq Primate\":\"seq_in_prim\", \"Seq Human\":\"peptide_hum\", \"Start Genome\":\"start_genom\", \"Stop Genome\":\"stop_genom\", \"E-value\":\"e_value\"},axis=1)\n",
    "tblastn.to_sql(con=conn, name='tblastn_match', index=False, if_exists=\"append\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
