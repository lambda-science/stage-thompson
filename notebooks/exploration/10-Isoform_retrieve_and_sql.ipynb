{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import grequests\n",
    "from Bio.SubsMat import MatrixInfo as matlist\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import math\n",
    "import numpy as np\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    # Function: Merge two dictionarry together. Used to merge json response after being converted to dict.\n",
    "    # Parameters:\n",
    "    # \t\tx: (dict) first dict\n",
    "    #       y: (dict) second dict\n",
    "    # Return:\n",
    "    # \t\tz: (dict) merged dict\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "def importJson(filePath):\n",
    "    # Function: Import json file. Json file can contains multiple json reponse with one json response to each line.\n",
    "    # Parameters:\n",
    "    # \t\tfilePath: (str) path to the json file to import\n",
    "    # Return:\n",
    "    # \t\tMyJsonFull: (dict) json file merged and converted to a dictionnary\n",
    "    data_dict = []\n",
    "    with open(filePath) as json_data:\n",
    "        for i in json_data:\n",
    "            data_dict.append(json.loads(i))\n",
    "    MyJsonFull = data_dict[0]\n",
    "    for i in data_dict[1:]:\n",
    "        MyJsonFull = merge_two_dicts(MyJsonFull, i)\n",
    "    return MyJsonFull\n",
    "\n",
    "def fasta2List(pathFasta):\n",
    "    f = open(pathFasta, \"r\")\n",
    "    title = []\n",
    "    seq = []\n",
    "    seq_temp = []\n",
    "    for line in f:\n",
    "        if line[0] == \">\":\n",
    "            seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "            title.append(line.replace(\"\\n\", \"\"))\n",
    "            seq_temp = []\n",
    "        else:\n",
    "            seq_temp.append(line)\n",
    "    seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "    seq.pop(0)\n",
    "    dictionary = dict(zip(title, seq))\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch = pd.read_sql_query(\"SELECT * FROM mismatch\", conn)\n",
    "mismatch = mismatch.astype({\"exon_start_prim\": \"Int64\", \"exon_stop_prim\":\"Int64\", \"exon_start_hum\": \"Int64\", \"exon_stop_hum\":\"Int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flagging isoform\n",
    "# Prot to gene\n",
    "f = open(\"../../temp/isoform/uniprot_to_gene_human.tab\", \"w\")\n",
    "uniq_human_prot = list(set(mismatch[\"prot_hum\"].to_list()))\n",
    "URL = \"https://www.uniprot.org/uploadlists/\"\n",
    "params = {\n",
    "    \"from\": \"ACC+ID\",\n",
    "    \"to\": \"ENSEMBL_ID\",\n",
    "    \"format\": \"tab\",\n",
    "    \"query\": ' '.join(uniq_human_prot)\n",
    "}\n",
    "\n",
    "r = requests.post(URL, data=params)\n",
    "f.write(r.text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flagging isoform\n",
    "# Gene to Transcript\n",
    "ID_file = pd.read_csv(\"../../temp/isoform/uniprot_to_gene_human.tab\", sep=\"\\t\")\n",
    "url = \"https://rest.ensembl.org/lookup/id/\"\n",
    "headers = {\"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\"}\n",
    "\n",
    "params = []\n",
    "for i in range(0, len(ID_file.index), 300):\n",
    "    try:\n",
    "        params.append(\n",
    "            {\"ids\": ID_file.iloc[i:i+300, 1].tolist(), \"expand\": \"1\"})\n",
    "    except:\n",
    "        params.append({\"ids\": ID_file.iloc[i:, 1].tolist(), \"expand\": \"1\"})\n",
    "\n",
    "rs = [grequests.post(url, headers=headers, data=json.dumps(i))\n",
    "        for i in params]\n",
    "all_response = grequests.map(rs, size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../../temp/isoform/json_dump_transcript.json\", \"a\")\n",
    "for response in all_response:\n",
    "    try:\n",
    "        f.write(json.dumps(response.json())+\"\\n\")\n",
    "    except:\n",
    "        pass\n",
    "f.close()\n",
    "\n",
    "transcript = importJson(\"../../temp/isoform/json_dump_transcript.json\")\n",
    "f = open(\"../../temp/isoform/gene_to_transcript.tab\", \"w\")\n",
    "f.write(\"gene\\ttranscript\\n\")\n",
    "for i in transcript:\n",
    "    for j in range(len(transcript[i][\"Transcript\"])):\n",
    "        f.write(i+\"\\t\"+transcript[i][\"Transcript\"][j][\"id\"]+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_file = pd.read_csv(\"../../temp/isoform/uniprot_to_gene_human.tab\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcript to prot\n",
    "# Flagging isoform\n",
    "\n",
    "\n",
    "f = open(\"../../temp/isoform/transcript_to_prot.tab\", \"w\")\n",
    "\n",
    "ID_transcript = pd.read_csv(\"../../temp/isoform/gene_to_transcript.tab\", sep=\"\\t\")\n",
    "uniq_human_trans = list(set(ID_transcript[\"transcript\"].to_list()))\n",
    "\n",
    "URL = \"https://www.uniprot.org/uploadlists/\"\n",
    "params = {\n",
    "    \"from\": \"ENSEMBL_TRS_ID\",\n",
    "    \"to\": \"ACC\",\n",
    "    \"format\": \"tab\",\n",
    "    \"query\": ' '.join(uniq_human_trans)\n",
    "}\n",
    "\n",
    "r = requests.post(URL, data=params)\n",
    "f.write(r.text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTER LES COMMANDES SUIVANTE DANS UN TERMINAL AVANT LA PROCHAIANE CELLULE:\n",
    "# Ces commandes permettent de récupérer les séquences fasta des ID Uniprot des isoformes.\n",
    "# cat temp/isoform/transcript_to_prot.tab | cut -f2 > temp/isoform/all_isoform.id\n",
    "# ./bin/retrieve_seq_isoform.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe pour Protein\n",
    "conn = sqlite3.connect(\"../../mismatch_db.db\")\n",
    "uniprot_ID = []\n",
    "uniprot_Seq = []\n",
    "#Prot_list = fasta2List(\"../../temp/isoform/uniprot_iso/final_all_isoform.fasta\")\n",
    "Prot_list = fasta2List(\"../../temp/isoform/final_all_isoform.fasta\")\n",
    "for key, val in Prot_list.items():\n",
    "    myKey = key[1:].split(\" \")\n",
    "    uniprot_ID.append(myKey[0])\n",
    "    uniprot_Seq.append(val)\n",
    "dict_uniprot = {\"uniprot_ID\": uniprot_ID, \"uniprot_Seq\": uniprot_Seq}\n",
    "df_prot = pd.DataFrame(dict_uniprot)\n",
    "df_prot[\"organism\"] = 9606\n",
    "df_prot = df_prot.rename(columns={\"uniprot_ID\": \"prot_ID\", \"uniprot_Seq\":\"sequence\"})\n",
    "df_prot.to_sql(con=conn, name='protein_hum_isoform', index=False, if_exists=\"append\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('stage-env': conda)",
   "language": "python",
   "name": "python37664bitstageenvconda39052ae7dd75404f9bdb3226673ac6d7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}